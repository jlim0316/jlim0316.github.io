---
title:  "CNN-convolution-neural-network"
last_modified_at: 2021-04-13T19:32:58-04:00
categories: 
  - DeepLearning
tags:
  - cnn, mnist
use_math: true
toc: true
toc_label: "Getting Started"
---

<h1 id="cnn-convolution-neural-network">CNN (Convolution Neural Network)</h1>
<p>CNN (Convolution Neural Network) 이란, 인간이 눈으로 물체를 인식하는 것을 모방하여 컴퓨터가 이미지를 처리하는 기술이다. CNN의 구조는 아래와 같다.</p>
<pre class=" language-mermaid"><svg id="mermaid-svg-Iygei146fUi8G7MC" width="100%" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" height="206" style="max-width: 676.9000244140625px;" viewBox="0 0 676.9000244140625 206"><style>#mermaid-svg-Iygei146fUi8G7MC{font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:16px;fill:#000000;}#mermaid-svg-Iygei146fUi8G7MC .error-icon{fill:#552222;}#mermaid-svg-Iygei146fUi8G7MC .error-text{fill:#552222;stroke:#552222;}#mermaid-svg-Iygei146fUi8G7MC .edge-thickness-normal{stroke-width:2px;}#mermaid-svg-Iygei146fUi8G7MC .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg-Iygei146fUi8G7MC .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg-Iygei146fUi8G7MC .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg-Iygei146fUi8G7MC .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg-Iygei146fUi8G7MC .marker{fill:#666;stroke:#666;}#mermaid-svg-Iygei146fUi8G7MC .marker.cross{stroke:#666;}#mermaid-svg-Iygei146fUi8G7MC svg{font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg-Iygei146fUi8G7MC .label{font-family:"trebuchet ms",verdana,arial,sans-serif;color:#000000;}#mermaid-svg-Iygei146fUi8G7MC .cluster-label text{fill:#333;}#mermaid-svg-Iygei146fUi8G7MC .cluster-label span{color:#333;}#mermaid-svg-Iygei146fUi8G7MC .label text,#mermaid-svg-Iygei146fUi8G7MC span{fill:#000000;color:#000000;}#mermaid-svg-Iygei146fUi8G7MC .node rect,#mermaid-svg-Iygei146fUi8G7MC .node circle,#mermaid-svg-Iygei146fUi8G7MC .node ellipse,#mermaid-svg-Iygei146fUi8G7MC .node polygon,#mermaid-svg-Iygei146fUi8G7MC .node path{fill:#eee;stroke:#999;stroke-width:1px;}#mermaid-svg-Iygei146fUi8G7MC .node .label{text-align:center;}#mermaid-svg-Iygei146fUi8G7MC .node.clickable{cursor:pointer;}#mermaid-svg-Iygei146fUi8G7MC .arrowheadPath{fill:#333333;}#mermaid-svg-Iygei146fUi8G7MC .edgePath .path{stroke:#666;stroke-width:1.5px;}#mermaid-svg-Iygei146fUi8G7MC .flowchart-link{stroke:#666;fill:none;}#mermaid-svg-Iygei146fUi8G7MC .edgeLabel{background-color:white;text-align:center;}#mermaid-svg-Iygei146fUi8G7MC .edgeLabel rect{opacity:0.5;background-color:white;fill:white;}#mermaid-svg-Iygei146fUi8G7MC .cluster rect{fill:hsl(210,66.6666666667%,95%);stroke:#26a;stroke-width:1px;}#mermaid-svg-Iygei146fUi8G7MC .cluster text{fill:#333;}#mermaid-svg-Iygei146fUi8G7MC .cluster span{color:#333;}#mermaid-svg-Iygei146fUi8G7MC div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:12px;background:hsl(-160,0%,93.3333333333%);border:1px solid #26a;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg-Iygei146fUi8G7MC:root{--mermaid-font-family:"trebuchet ms",verdana,arial,sans-serif;}#mermaid-svg-Iygei146fUi8G7MC flowchart{fill:apa;}</style><g><g class="output"><g class="clusters"></g><g class="edgePaths"><g class="edgePath LS-A LE-B" id="L-A-B" style="opacity: 1;"><path class="path" d="M77.05490621573401,109.65490545279454L119.4000015258789,79L144.4000015258789,79" marker-end="url(https://stackedit.io/app#arrowhead498)" style="fill:none"></path><defs><marker id="arrowhead498" viewBox="0 0 10 10" refX="9" refY="5" markerUnits="strokeWidth" markerWidth="8" markerHeight="6" orient="auto"><path d="M 0 0 L 10 5 L 0 10 z" class="arrowheadPath" style="stroke-width: 1; stroke-dasharray: 1, 0;"></path></marker></defs></g><g class="edgePath LS-A LE-C" id="L-A-C" style="opacity: 1;"><path class="path" d="M77.05490532016654,145.34509391689403L119.4000015258789,175L175.0875015258789,175" marker-end="url(https://stackedit.io/app#arrowhead499)" style="fill:none"></path><defs><marker id="arrowhead499" viewBox="0 0 10 10" refX="9" refY="5" markerUnits="strokeWidth" markerWidth="8" markerHeight="6" orient="auto"><path d="M 0 0 L 10 5 L 0 10 z" class="arrowheadPath" style="stroke-width: 1; stroke-dasharray: 1, 0;"></path></marker></defs></g><g class="edgePath LS-B LE-E" id="L-B-E" style="opacity: 1;"><path class="path" d="M291.4156265258789,62.17756173874176L427.6500015258789,31L563.8843765258789,31" marker-end="url(https://stackedit.io/app#arrowhead500)" style="fill:none"></path><defs><marker id="arrowhead500" viewBox="0 0 10 10" refX="9" refY="5" markerUnits="strokeWidth" markerWidth="8" markerHeight="6" orient="auto"><path d="M 0 0 L 10 5 L 0 10 z" class="arrowheadPath" style="stroke-width: 1; stroke-dasharray: 1, 0;"></path></marker></defs></g><g class="edgePath LS-B LE-F" id="L-B-F" style="opacity: 1;"><path class="path" d="M291.4156265258789,95.82243826125824L427.6500015258789,127L580.6890640258789,127" marker-end="url(https://stackedit.io/app#arrowhead501)" style="fill:none"></path><defs><marker id="arrowhead501" viewBox="0 0 10 10" refX="9" refY="5" markerUnits="strokeWidth" markerWidth="8" markerHeight="6" orient="auto"><path d="M 0 0 L 10 5 L 0 10 z" class="arrowheadPath" style="stroke-width: 1; stroke-dasharray: 1, 0;"></path></marker></defs></g></g><g class="edgeLabels"><g class="edgeLabel" transform="" style="opacity: 1;"><g transform="translate(0,0)" class="label"><rect rx="0" ry="0" width="0" height="0"></rect><foreignObject width="0" height="0"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span id="L-L-A-B" class="edgeLabel L-LS-A' L-LE-B"></span></div></foreignObject></g></g><g class="edgeLabel" transform="" style="opacity: 1;"><g transform="translate(0,0)" class="label"><rect rx="0" ry="0" width="0" height="0"></rect><foreignObject width="0" height="0"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span id="L-L-A-C" class="edgeLabel L-LS-A' L-LE-C"></span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(427.6500015258789,31)" style="opacity: 1;"><g transform="translate(-60.8203125,-13)" class="label"><rect rx="0" ry="0" width="121.640625" height="26"></rect><foreignObject width="121.640625" height="26"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span id="L-L-B-E" class="edgeLabel L-LS-B' L-LE-E">이미지 특징 추출</span></div></foreignObject></g></g><g class="edgeLabel" transform="translate(427.6500015258789,127)" style="opacity: 1;"><g transform="translate(-111.234375,-13)" class="label"><rect rx="0" ry="0" width="222.46875" height="26"></rect><foreignObject width="222.46875" height="26"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;"><span id="L-L-B-F" class="edgeLabel L-LS-B' L-LE-F">위치특성 남기고 파라미터 줄임</span></div></foreignObject></g></g></g><g class="nodes"><g class="node default" id="flowchart-A-2570" transform="translate(51.20000076293945,127)" style="opacity: 1;"><polygon points="43.2,0 86.4,-43.2 43.2,-86.4 0,-43.2" transform="translate(-43.2,43.2)" class="label-container"></polygon><g class="label" transform="translate(0,0)"><g transform="translate(-15,-13)"><foreignObject width="30" height="26"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;">CNN</div></foreignObject></g></g></g><g class="node default" id="flowchart-B-2571" transform="translate(217.9078140258789,79)" style="opacity: 1;"><rect rx="5" ry="5" x="-73.5078125" y="-23" width="147.015625" height="46" class="label-container"></rect><g class="label" transform="translate(0,0)"><g transform="translate(-63.5078125,-13)"><foreignObject width="127.015625" height="26"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;">Feature Extractor</div></foreignObject></g></g></g><g class="node default" id="flowchart-C-2573" transform="translate(217.9078140258789,175)" style="opacity: 1;"><rect rx="5" ry="5" x="-42.8203125" y="-23" width="85.640625" height="46" class="label-container"></rect><g class="label" transform="translate(0,0)"><g transform="translate(-32.8203125,-13)"><foreignObject width="65.640625" height="26"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;">Classifier</div></foreignObject></g></g></g><g class="node default" id="flowchart-E-2575" transform="translate(616.3921890258789,31)" style="opacity: 1;"><rect rx="5" ry="5" x="-52.5078125" y="-23" width="105.015625" height="46" class="label-container"></rect><g class="label" transform="translate(0,0)"><g transform="translate(-42.5078125,-13)"><foreignObject width="85.015625" height="26"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;">Convolution</div></foreignObject></g></g></g><g class="node default" id="flowchart-F-2577" transform="translate(616.3921890258789,127)" style="opacity: 1;"><rect rx="5" ry="5" x="-35.703125" y="-23" width="71.40625" height="46" class="label-container"></rect><g class="label" transform="translate(0,0)"><g transform="translate(-25.703125,-13)"><foreignObject width="51.40625" height="26"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; white-space: nowrap;">Pooling</div></foreignObject></g></g></g></g></g></g></svg></pre>
<ul>
<li><strong>Feature Extractor</strong>는 이미지의 특징을 추출해주는 기능으로 Conv2D, Maxpooling 레이어로 구성된다.</li>
<li><strong>Convolution</strong> 연산을 중첩할수록 더 넓은 범위, 많은 양의 위치정보를 고려하여 연산할 수 있게 된다.</li>
<li><strong>Pooling</strong> 연산은 Convolution 이후에 적용함으로써, 정보를 단순화 하며, 공간적인 특성을 조금 더 강조하는 역할을 담당한다.</li>
<li><strong>Classifier</strong>는 추출된 특징들로 실제 클래스를 분류하는 Fully Connected layer로 구성된다.</li>
</ul>
<br>
<hr>
<p>딥러닝에서 자주 쓰이는 <code>Epoch</code>, <code>Iteration</code>, <code>mini-batch</code>의 기본 개념과 직관적인 이해를 하고 넘어가려고 한다.</p>

<table>
<thead>
<tr>
<th>용어</th>
<th>설명</th>
</tr>
</thead>
<tbody>
<tr>
<td>1 Epoch</td>
<td>모든 학습 데이터로 학습이 업데이트 진행되면 한번의 epoch이 끝난 것</td>
</tr>
<tr>
<td>1 Iteration</td>
<td>한번의 업데이터 진행 단위</td>
</tr>
<tr>
<td>mini-batch</td>
<td>iteration을 진행할 학습 데이터의 부분 묶음</td>
</tr>
</tbody>
</table><br>
기본 개념에 대한 이해도는 아래 문제를 풀면 확인할 수 있다.
<blockquote>
<p>학습 데이터가 5만 건이 있는데, 이때 mini-batch size가 1,000이다.<br>
1 epoch을 수행하기 위해서 얼마의 iteration이 필요할까?<br>
답:  <strong>50 iteration</strong> (Epoch과 Mini-batch를 지정하면 iteration은 자동 계산됨)</p>
</blockquote>
<p>MNIST 데이터의 경우, 5만 장의 학습용 이미지와 정답 쌍이 주어진다.</p>
<p>한번에 학습하기 힘들만큼 방대한 데이터를, 낮은 성능 컴퓨터로도 학습이 가능하도록 데이터를 작게 쪼개는 것이다.</p>
<p>마치 값이 큰 금액을 살 때 여러 개월 할부로 금액을 지불하는 것과 같다. 이 때, <strong>할부액이 Mini-batch</strong> 개념에 해당하며 <strong>할부 개월 수가 Iteration</strong>에 해당한다.</p>
<hr>
<h2 id="mnist--손글씨-숫자-인식하기">MNIST : 손글씨 숫자 인식하기</h2>
<p>MNIST 데이터셋은 손글씨로 쓴 0~9까지의 숫자로 이뤄진 흑백 이미지 데이터셋이다.<br>
사람마다 글쓰는 방식이 다르다.<br>
<img src="https://user-images.githubusercontent.com/41845290/114508523-6d0fff80-9c6f-11eb-999d-a1b29fc6cca3.png" alt="image"><br>
힘을 주어 굵게 쓰는 사람, 기울여 적는 사람, 흘려쓰는 사람 등 다양한 글씨체가 존재한다.<br>
사람만 인식해오던 <strong>이미지</strong>를 이제는 이걸 <strong>기계도</strong> 인식할 수 있다.</p>
<p>다만, 이를 위해서 계산할 수 있는 형태의 숫자 데이터 형태로 변환하고,  가중합과 비선형 함수 연산 과정을 거쳐야 한다. (인공신경망에 이미지를 입력하기 위해서는 가중합과 비선형 함수 연산이 필요하기 때문이다.)</p>
<p>먼저 이미지를 수치화한 데이터로 불러오는 과정이 필요하다.<br>
<img src="https://user-images.githubusercontent.com/41845290/114509393-67ff8000-9c70-11eb-9265-73b8021448b7.png" alt="image"><br>
글씨가 칠해진  검은 부분은 1로 표기하고, 글씨가 쓰여지지 않은 배경부분은 0으로 표시했다. (사실상 진하기에 따라 0~1사이 인데 편의상 0, 1 이라 고려하자.)<br>
그러면 실수값으로 이루어진 2차원 매트릭스 형태를 갖춘 셈이다. (컬러 이미지의 경우 3차원 텐서로 이루어진다.)</p>

<table>
<thead>
<tr>
<th>입력 이미지</th>
<th>정답 벡터</th>
</tr>
</thead>
<tbody>
<tr>
<td>입력 이미지</td>
<td>정답 벡터</td>
</tr>
<tr>
<td>입력 이미지</td>
<td>정답 벡터</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
</tr>
<tr>
<td>입력 이미지</td>
<td>정답 벡터</td>
</tr>
</tbody>
</table><p>기계가 숫자를 맞추기 위해서 위 표처럼  생긴 데이터 셋을 학습하는 과정이 필요하며,  함수의 weight(기울기)와 bias(절편)을 변경해가며 데이터를 통해 스스로 찾아나간다.</p>
<p>bias은 뉴런이 데이터를 가중합한 뒤 더해주는 실수값, weight는 위 신경망 그림의 화살표 선 하나 하나에 해당하는 값들로, 가중치이다.</p>
<h2 id="section"><img src="https://user-images.githubusercontent.com/41845290/114511103-70f15100-9c72-11eb-82b8-f6ed51149d87.png" alt="image"></h2>
<h3 id="mnist--실습">MNIST : 실습</h3>
<p>MNIST 데이터셋을 활용한 텐서플로 실습을 해보고자 한다.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Flatten
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential
</code></pre>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># 데이터 로드</span>
mnist <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>mnist
<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span> 

<span class="token comment"># 0~255의 픽셀 값을 0~1로 조정</span>
x_train<span class="token punctuation">,</span> x_test <span class="token operator">=</span> x_train <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> x_test <span class="token operator">/</span> <span class="token number">255.0</span>

<span class="token comment"># shape 조정</span>
x_train <span class="token operator">=</span> x_train<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">60000</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
x_test <span class="token operator">=</span> x_test<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 정답 label을 길이 10 벡터화 (0,1,...,9 의 갯수가 10이므로)</span>
y_train <span class="token operator">=</span> tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> depth<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
y_test <span class="token operator">=</span> tf<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> depth<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

<span class="token comment"># Training set으로부터 Validation set을 따로 분리</span>
x_train<span class="token punctuation">,</span> x_val <span class="token operator">=</span> x_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">50000</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x_train<span class="token punctuation">[</span><span class="token number">50000</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
y_train<span class="token punctuation">,</span> y_val <span class="token operator">=</span> y_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">50000</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y_train<span class="token punctuation">[</span><span class="token number">50000</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
</code></pre>
<p>데이터셋의 shape은 아래와 같다.</p>
<p>입력 데이터의 경우, (28,28,1) 짜리의 이미지가 학습용으로 5만 장, 검증용으로 1만 장, 테스트용으로 1만 장, 총 7만 장의 이미지가 있다.</p>
<p>정답 데이터(라벨)의 경우 길이 10짜리의 벡터가 학습용으로 역시 5만 개, 검증용 1만 개, 테스트용 1만 개 총 7만 개가 있다.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"학습용 이미지의 shape : \t"</span><span class="token punctuation">,</span> x_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"검증용 이미지의 shape : \t"</span><span class="token punctuation">,</span> x_val<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"테스트용 이미지의 shape : \t"</span><span class="token punctuation">,</span> x_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"학습용 라벨(정답)의 shape : \t"</span><span class="token punctuation">,</span> y_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"검증용 라벨(정답)의 shape : \t"</span><span class="token punctuation">,</span> y_val<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"테스트용 라벨(정답)의 shape : \t"</span><span class="token punctuation">,</span> y_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  
</code></pre>
<pre><code>학습용 이미지의 shape : 	 (50000, 28, 28, 1)
검증용 이미지의 shape : 	 (10000, 28, 28, 1)
테스트용 이미지의 shape : 	 (10000, 28, 28, 1)

학습용 라벨(정답)의 shape : 	 (50000, 10)
검증용 라벨(정답)의 shape : 	 (10000, 10)
테스트용 라벨(정답)의 shape : 	 (10000, 10)
</code></pre>
<pre class=" language-python"><code class="prism  language-python"><span class="token triple-quoted-string string">"""def preprocess(features):
  
    img = features['image']
    label = features['label']
    img = tf.image.resize(img, [224, 224])
    img = tf.cast(img, tf.float32)
    img = img / 255.0

    return img, label

train_dataset = dataset.map(preprocess).batch(32)"""</span>
</code></pre>
<p>mnist의 경우 shape이 모두 같아서 따로 전처리가 필요없었지만, 이미지 사이즈가 전부 다른 경우 변경해주어야 한다.</p>
<p>해당하는 Dataset의 다양한 손글씨 이미지 중 index가 1001인 이미지는 4인지 7인지 애매하다.<br>
정답을 확인해보면 7이라 쓴 손 글씨이다.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

INDEX <span class="token operator">=</span> <span class="token number">1001</span>

plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>x_train<span class="token punctuation">[</span>INDEX<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'gray_r'</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"입력 이미지의 shape : "</span><span class="token punctuation">,</span> x_train<span class="token punctuation">[</span>INDEX<span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"해당 데이터에 대한 label : "</span><span class="token punctuation">,</span> y_train<span class="token punctuation">[</span>INDEX<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>입력 이미지의 shape :  (28, 28, 1)
해당 데이터에 대한 label :  tf.Tensor([0. 0. 0. 0. 0. 0. 0. 1. 0. 0.], shape=(10,), dtype=float32)
</code></pre>
<p><img src="https://user-images.githubusercontent.com/41845290/114538330-3bf2f780-9c8e-11eb-87f4-9e4676e5533e.png" alt="output_8_1"></p>
<ul>
<li>Flatten() 레이어는 28*28 픽셀의 이미지를 차원을 무시하고, 납작하게 눌러(flatten) 1차원의 열벡터로 펼치는 역할을 한다.</li>
<li>Dense 레이어는 FNN의 한 층을 구성한다. 첫 번째 인자는 해당 레이어의 뉴런(노드) 수를 의미합니다. 각 뉴런이 가중합하고 난 후 적용할 비선형 함수를 지정한다. (여기 사용된 시그모이드 함수는 S자 모양이며 0~1로 변환해주는 함수이다.)</li>
<li>마지막 Dense 레이어는 output으로 출력할 뉴런 수를 써야 한다. (10개의 숫자로 분류해야 하므로 10)</li>
</ul>
<pre class=" language-python"><code class="prism  language-python">model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
                    Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    Dense<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span> <span class="token comment"># 출력할 뉴런 수 지정, 분류 과제이므로 softmax</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<pre class=" language-python"><code class="prism  language-python">model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_2 (Flatten)          (None, 784)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 15)                11775     
_________________________________________________________________
dense_5 (Dense)              (None, 10)                160       
=================================================================
Total params: 11,935
Trainable params: 11,935
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<p>훈련에 필요한 파라미터 업데이트 기법과 loss 함수를 선택한다.</p>
<p>파라미터 업데이트 방식(optimzer)은 <strong>SGD(Stochastic Gradient Descent, 경사하강법)</strong> 을,<br>
Loss 함수로는 <strong>MSE(Mean Squared Error) Loss</strong> 를, 성능 평가는 <strong>분류정확도(accuracy)</strong> 를 기준으로 학습하고자 한다.</p>
<pre class=" language-python"><code class="prism  language-python">my_opt <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span><span class="token punctuation">)</span>
my_loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>MeanSquaredError<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>my_opt<span class="token punctuation">,</span> loss<span class="token operator">=</span>my_loss<span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<pre class=" language-python"><code class="prism  language-python">EPOCHS <span class="token operator">=</span> <span class="token number">5</span>
BATCH <span class="token operator">=</span> <span class="token number">32</span>
history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token operator">=</span>x_train<span class="token punctuation">,</span> y<span class="token operator">=</span>y_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>BATCH<span class="token punctuation">,</span> epochs<span class="token operator">=</span>EPOCHS<span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>x_val<span class="token punctuation">,</span> y_val<span class="token punctuation">)</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Train on 50000 samples, validate on 10000 samples
Epoch 1/5
50000/50000 [==============================] - 3s 52us/sample - loss: 0.0917 - acc: 0.1288 - val_loss: 0.0918 - val_acc: 0.1317
Epoch 2/5
50000/50000 [==============================] - 2s 45us/sample - loss: 0.0915 - acc: 0.1379 - val_loss: 0.0916 - val_acc: 0.1398
Epoch 3/5
50000/50000 [==============================] - 2s 46us/sample - loss: 0.0913 - acc: 0.1475 - val_loss: 0.0914 - val_acc: 0.1484
Epoch 4/5
50000/50000 [==============================] - 2s 46us/sample - loss: 0.0912 - acc: 0.1557 - val_loss: 0.0912 - val_acc: 0.1557
Epoch 5/5
50000/50000 [==============================] - 2s 50us/sample - loss: 0.0910 - acc: 0.1642 - val_loss: 0.0911 - val_acc: 0.1632
</code></pre>
<p>학습용 데이터로 모델 학습이 완료됐다.<br>
이제 테스트 데이터를 모델에 입력하고, 추론 결과를 꺼내 테스트셋 성능을 체크하자.<br>
model.evaluate() 기능을 활용하면 모델의 추론 결과를 확인할 수 있다.</p>
<pre class=" language-python"><code class="prism  language-python">model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span>
</code></pre>
<pre><code>10000/10000 [==============================] - 0s 26us/sample - loss: 0.0909 - acc: 0.1695





[0.09087827944755554, 0.1695]
</code></pre>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>EPOCHS<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Train"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>EPOCHS<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_acc'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Validation"</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Accuracy Graph"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>EPOCHS<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>EPOCHS<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p><img src="https://user-images.githubusercontent.com/41845290/114538388-4f05c780-9c8e-11eb-8431-cf5a6cb50355.png" alt="output_17_0"></p>
<pre class=" language-python"><code class="prism  language-python">plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>EPOCHS<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Train"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>EPOCHS<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Validation"</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Loss Graph"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>EPOCHS<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>EPOCHS<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p><img src="https://user-images.githubusercontent.com/41845290/114538416-57f69900-9c8e-11eb-9875-964baf5b95bf.png" alt="output_18_0"></p>
<p>5번의 반복학습동안 Accuracy는 점점 증가하고 Loss는 점점 떨어지는 걸 볼 수 있다.</p>
<p><strong>참고 링크</strong></p>
<ul>
<li>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/activations">tf.keras.activations docs</a></p>
</li>
<li>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/losses">tf.keras.losses docs</a></p>
</li>
<li>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers">tf.keras.optimizer docs</a></p>
</li>
</ul>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">def</span> <span class="token function">plot_history</span><span class="token punctuation">(</span>histories<span class="token punctuation">)</span><span class="token punctuation">:</span>
  plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

  <span class="token keyword">for</span> history <span class="token keyword">in</span> histories<span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'training'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'validation'</span><span class="token punctuation">)</span>

  plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epochs'</span><span class="token punctuation">)</span>
  plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'ACC'</span><span class="token punctuation">)</span>
  plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>

  plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token builtin">max</span><span class="token punctuation">(</span>history<span class="token punctuation">.</span>epoch<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<h1 id="mission-1--베이스-모델-만들고-학습하기">MISSION #1 : 베이스 모델 만들고 학습하기</h1>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># 아래 코드에서 MISSION 내용을 반영하여 학습하세요</span>

model_m1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
 
model_m1<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

history_m1 <span class="token operator">=</span> model_m1<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>x_val<span class="token punctuation">,</span> y_val<span class="token punctuation">)</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
result_m1 <span class="token operator">=</span> model_m1<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>  y_test<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Train on 50000 samples, validate on 10000 samples
Epoch 1/10
50000/50000 - 3s - loss: 0.3606 - accuracy: 0.8995 - val_loss: 0.1914 - val_accuracy: 0.9470
Epoch 2/10
50000/50000 - 3s - loss: 0.1776 - accuracy: 0.9479 - val_loss: 0.1424 - val_accuracy: 0.9590
Epoch 3/10
50000/50000 - 3s - loss: 0.1292 - accuracy: 0.9614 - val_loss: 0.1257 - val_accuracy: 0.9637
Epoch 4/10
50000/50000 - 3s - loss: 0.1040 - accuracy: 0.9694 - val_loss: 0.1141 - val_accuracy: 0.9677
Epoch 5/10
50000/50000 - 2s - loss: 0.0864 - accuracy: 0.9734 - val_loss: 0.1075 - val_accuracy: 0.9676
Epoch 6/10
50000/50000 - 2s - loss: 0.0737 - accuracy: 0.9776 - val_loss: 0.1072 - val_accuracy: 0.9700
Epoch 7/10
50000/50000 - 3s - loss: 0.0638 - accuracy: 0.9816 - val_loss: 0.1008 - val_accuracy: 0.9719
Epoch 8/10
50000/50000 - 3s - loss: 0.0566 - accuracy: 0.9832 - val_loss: 0.1009 - val_accuracy: 0.9717
Epoch 9/10
50000/50000 - 3s - loss: 0.0504 - accuracy: 0.9850 - val_loss: 0.0972 - val_accuracy: 0.9719
Epoch 10/10
50000/50000 - 3s - loss: 0.0429 - accuracy: 0.9870 - val_loss: 0.0988 - val_accuracy: 0.9728
10000/10000 - 0s - loss: 0.0911 - accuracy: 0.9723
</code></pre>
<pre class=" language-python"><code class="prism  language-python"><span class="token comment"># optimizer의 사용</span>

model_sgd <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model_sgd<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'sgd'</span><span class="token punctuation">,</span>loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   
history_sgd <span class="token operator">=</span> model_sgd<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>x_val<span class="token punctuation">,</span> y_val<span class="token punctuation">)</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
result_sgd <span class="token operator">=</span> model_sgd<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>  y_test<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment">################################################################</span>

model_sgdm <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span> 

sgdm <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>  

model_sgdm<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>sgdm<span class="token punctuation">,</span>loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
history_sgdm <span class="token operator">=</span> model_sgdm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>x_val<span class="token punctuation">,</span> y_val<span class="token punctuation">)</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
result_sgdm <span class="token operator">=</span> model_sgdm<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>  y_test<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Train on 50000 samples, validate on 10000 samples
Epoch 1/10
50000/50000 - 3s - loss: 1.8230 - accuracy: 0.5014 - val_loss: 1.3194 - val_accuracy: 0.7501
Epoch 2/10
50000/50000 - 2s - loss: 1.0785 - accuracy: 0.7721 - val_loss: 0.8265 - val_accuracy: 0.8334
Epoch 3/10
50000/50000 - 2s - loss: 0.7683 - accuracy: 0.8246 - val_loss: 0.6315 - val_accuracy: 0.8592
Epoch 4/10
50000/50000 - 2s - loss: 0.6310 - accuracy: 0.8479 - val_loss: 0.5355 - val_accuracy: 0.8699
Epoch 5/10
50000/50000 - 2s - loss: 0.5555 - accuracy: 0.8616 - val_loss: 0.4791 - val_accuracy: 0.8788
Epoch 6/10
50000/50000 - 2s - loss: 0.5074 - accuracy: 0.8702 - val_loss: 0.4412 - val_accuracy: 0.8860
Epoch 7/10
50000/50000 - 2s - loss: 0.4738 - accuracy: 0.8762 - val_loss: 0.4148 - val_accuracy: 0.8901
Epoch 8/10
50000/50000 - 2s - loss: 0.4487 - accuracy: 0.8803 - val_loss: 0.3949 - val_accuracy: 0.8951
Epoch 9/10
50000/50000 - 3s - loss: 0.4292 - accuracy: 0.8839 - val_loss: 0.3793 - val_accuracy: 0.8982
Epoch 10/10
50000/50000 - 3s - loss: 0.4134 - accuracy: 0.8870 - val_loss: 0.3664 - val_accuracy: 0.9004
10000/10000 - 0s - loss: 0.3795 - accuracy: 0.8971
Train on 50000 samples, validate on 10000 samples
Epoch 1/10
50000/50000 - 3s - loss: 0.3397 - accuracy: 0.9003 - val_loss: 0.1849 - val_accuracy: 0.9506
Epoch 2/10
50000/50000 - 2s - loss: 0.1759 - accuracy: 0.9480 - val_loss: 0.1405 - val_accuracy: 0.9602
Epoch 3/10
50000/50000 - 2s - loss: 0.1323 - accuracy: 0.9607 - val_loss: 0.1244 - val_accuracy: 0.9660
Epoch 4/10
50000/50000 - 2s - loss: 0.1086 - accuracy: 0.9679 - val_loss: 0.1208 - val_accuracy: 0.9656
Epoch 5/10
50000/50000 - 2s - loss: 0.0918 - accuracy: 0.9727 - val_loss: 0.1157 - val_accuracy: 0.9658
Epoch 6/10
50000/50000 - 2s - loss: 0.0799 - accuracy: 0.9758 - val_loss: 0.1396 - val_accuracy: 0.9609
Epoch 7/10
50000/50000 - 2s - loss: 0.0705 - accuracy: 0.9793 - val_loss: 0.1087 - val_accuracy: 0.9683
Epoch 8/10
50000/50000 - 2s - loss: 0.0628 - accuracy: 0.9815 - val_loss: 0.1030 - val_accuracy: 0.9711
Epoch 9/10
50000/50000 - 2s - loss: 0.0576 - accuracy: 0.9823 - val_loss: 0.1080 - val_accuracy: 0.9702
Epoch 10/10
50000/50000 - 2s - loss: 0.0518 - accuracy: 0.9844 - val_loss: 0.1015 - val_accuracy: 0.9724
10000/10000 - 0s - loss: 0.0970 - accuracy: 0.9722
</code></pre>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">def</span> <span class="token function">plot_history</span><span class="token punctuation">(</span>histories<span class="token punctuation">)</span><span class="token punctuation">:</span>
  plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

  <span class="token keyword">for</span> name<span class="token punctuation">,</span> history <span class="token keyword">in</span> histories<span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span>name<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 

  plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epochs'</span><span class="token punctuation">)</span>
  plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>
  plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>

  plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token builtin">max</span><span class="token punctuation">(</span>history<span class="token punctuation">.</span>epoch<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  
plot_history<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'SGD'</span><span class="token punctuation">,</span> history_sgd<span class="token punctuation">)</span><span class="token punctuation">,</span>
              <span class="token punctuation">(</span><span class="token string">'SGD w/momentum'</span><span class="token punctuation">,</span> history_sgdm<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<p><img src="https://user-images.githubusercontent.com/41845290/114538457-62189780-9c8e-11eb-98c6-0a9d0a7227d8.png" alt="output_25_0"></p>
<p>일반 SGD를 적용할 때보다 momentum 설정을 두어 가속도를 적용하니 모델 수렴속도가 훨씬 빨라졌다.</p>
<h1 id="mission-2--early-stopping-구현하기">MISSION #2 : Early stopping 구현하기</h1>
<p>tf.keras.callbacks.EarlyStopping: 매 epoch마다 validation accuracy를 체크해서, 최고기록을 갱신하지 못하는 경우가 n번 연속 지속된다면 학습을 거기서 중단하도록 하는 기능</p>
<p>Early stopping 콜백 기능에서, patience 옵션을 통해 조절한다.</p>
<ul>
<li>한번이라도 정확도가 감소하면 바로 stop하고 싶다 --&gt; patience=1</li>
<li>두번은 봐주자! 연속 두번 감소하면 그때 학습을 stop하자 --&gt; patience=2</li>
<li>…</li>
</ul>
<pre class=" language-python"><code class="prism  language-python">model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

early_stop <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>EarlyStopping<span class="token punctuation">(</span>monitor<span class="token operator">=</span><span class="token string">'val_accuracy'</span><span class="token punctuation">,</span> patience<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># 빈칸을 채워봅시다!</span>

history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>x_val<span class="token punctuation">,</span> y_val<span class="token punctuation">)</span><span class="token punctuation">,</span> callbacks<span class="token operator">=</span><span class="token punctuation">[</span>early_stop<span class="token punctuation">]</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>  y_test<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
plot_history<span class="token punctuation">(</span><span class="token punctuation">[</span>history<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Train on 50000 samples, validate on 10000 samples
Epoch 1/50
50000/50000 [==============================] - 1s 24us/sample - loss: 0.6274 - accuracy: 0.8313 - val_loss: 0.2887 - val_accuracy: 0.9220
Epoch 2/50
50000/50000 [==============================] - 1s 21us/sample - loss: 0.2780 - accuracy: 0.9237 - val_loss: 0.2294 - val_accuracy: 0.9374
Epoch 3/50
50000/50000 [==============================] - 1s 19us/sample - loss: 0.2254 - accuracy: 0.9360 - val_loss: 0.1978 - val_accuracy: 0.9461
Epoch 4/50
50000/50000 [==============================] - 1s 19us/sample - loss: 0.1913 - accuracy: 0.9461 - val_loss: 0.1794 - val_accuracy: 0.9510
Epoch 5/50
50000/50000 [==============================] - 1s 19us/sample - loss: 0.1674 - accuracy: 0.9521 - val_loss: 0.1604 - val_accuracy: 0.9546
Epoch 6/50
50000/50000 [==============================] - 1s 19us/sample - loss: 0.1491 - accuracy: 0.9566 - val_loss: 0.1511 - val_accuracy: 0.9568
Epoch 7/50
50000/50000 [==============================] - 1s 18us/sample - loss: 0.1340 - accuracy: 0.9620 - val_loss: 0.1406 - val_accuracy: 0.9597
Epoch 8/50
50000/50000 [==============================] - 1s 19us/sample - loss: 0.1219 - accuracy: 0.9656 - val_loss: 0.1365 - val_accuracy: 0.9608
Epoch 9/50
50000/50000 [==============================] - 1s 18us/sample - loss: 0.1112 - accuracy: 0.9681 - val_loss: 0.1279 - val_accuracy: 0.9631
Epoch 10/50
50000/50000 [==============================] - 1s 18us/sample - loss: 0.1019 - accuracy: 0.9710 - val_loss: 0.1216 - val_accuracy: 0.9650
Epoch 11/50
50000/50000 [==============================] - 1s 19us/sample - loss: 0.0949 - accuracy: 0.9733 - val_loss: 0.1187 - val_accuracy: 0.9660
Epoch 12/50
50000/50000 [==============================] - 1s 18us/sample - loss: 0.0877 - accuracy: 0.9750 - val_loss: 0.1216 - val_accuracy: 0.9641
Epoch 13/50
50000/50000 [==============================] - 1s 18us/sample - loss: 0.0827 - accuracy: 0.9765 - val_loss: 0.1148 - val_accuracy: 0.9669
Epoch 14/50
50000/50000 [==============================] - 1s 19us/sample - loss: 0.0772 - accuracy: 0.9784 - val_loss: 0.1125 - val_accuracy: 0.9686
Epoch 15/50
50000/50000 [==============================] - 1s 19us/sample - loss: 0.0719 - accuracy: 0.9801 - val_loss: 0.1114 - val_accuracy: 0.9669
Epoch 16/50
50000/50000 [==============================] - 1s 18us/sample - loss: 0.0679 - accuracy: 0.9803 - val_loss: 0.1132 - val_accuracy: 0.9676
Epoch 17/50
50000/50000 [==============================] - 1s 19us/sample - loss: 0.0636 - accuracy: 0.9821 - val_loss: 0.1110 - val_accuracy: 0.9662
10000/10000 - 0s - loss: 0.1093 - accuracy: 0.9693
</code></pre>
<p><img src="https://user-images.githubusercontent.com/41845290/114538495-6b096900-9c8e-11eb-8357-cf92daae14e8.png" alt="output_28_1"></p>
<h1 id="mission-3--capacity-조정-및-dropout-구현하기">MISSION #3 : Capacity 조정 및 Dropout 구현하기</h1>
<p>Dropout 기능도 마치 레이어처럼 추가할 수 있다.<br>
옵션으로 dropout할 비율을 0~1사이의 실수값으로 설정하면 된다.</p>
<pre class=" language-python"><code class="prism  language-python">
model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>rate<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 

history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span>x_val<span class="token punctuation">,</span> y_val<span class="token punctuation">)</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span>  y_test<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
plot_history<span class="token punctuation">(</span><span class="token punctuation">[</span>history<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Train on 50000 samples, validate on 10000 samples
Epoch 1/25
50000/50000 [==============================] - 1s 28us/sample - loss: 2.0367 - accuracy: 0.2543 - val_loss: 1.8258 - val_accuracy: 0.5967
Epoch 2/25
50000/50000 [==============================] - 1s 20us/sample - loss: 1.8397 - accuracy: 0.3337 - val_loss: 1.6413 - val_accuracy: 0.6660
Epoch 3/25
50000/50000 [==============================] - 1s 20us/sample - loss: 1.7247 - accuracy: 0.3539 - val_loss: 1.4828 - val_accuracy: 0.6837
Epoch 4/25
50000/50000 [==============================] - 1s 21us/sample - loss: 1.6403 - accuracy: 0.3609 - val_loss: 1.3638 - val_accuracy: 0.7048
Epoch 5/25
50000/50000 [==============================] - 1s 20us/sample - loss: 1.5916 - accuracy: 0.3642 - val_loss: 1.2772 - val_accuracy: 0.7000
Epoch 6/25
50000/50000 [==============================] - 1s 20us/sample - loss: 1.5552 - accuracy: 0.3695 - val_loss: 1.2067 - val_accuracy: 0.7046
Epoch 7/25
50000/50000 [==============================] - 1s 21us/sample - loss: 1.5291 - accuracy: 0.3718 - val_loss: 1.1487 - val_accuracy: 0.7377
Epoch 8/25
50000/50000 [==============================] - 1s 20us/sample - loss: 1.5043 - accuracy: 0.3809 - val_loss: 1.0973 - val_accuracy: 0.7338
Epoch 9/25
50000/50000 [==============================] - 1s 19us/sample - loss: 1.4925 - accuracy: 0.3787 - val_loss: 1.0583 - val_accuracy: 0.7703
Epoch 10/25
50000/50000 [==============================] - 1s 20us/sample - loss: 1.4646 - accuracy: 0.4112 - val_loss: 1.0312 - val_accuracy: 0.8555
Epoch 11/25
50000/50000 [==============================] - 1s 21us/sample - loss: 1.4066 - accuracy: 0.4592 - val_loss: 0.9356 - val_accuracy: 0.9169
Epoch 12/25
50000/50000 [==============================] - 1s 21us/sample - loss: 1.3468 - accuracy: 0.4699 - val_loss: 0.8533 - val_accuracy: 0.9365
Epoch 13/25
50000/50000 [==============================] - 1s 20us/sample - loss: 1.3137 - accuracy: 0.4747 - val_loss: 0.7903 - val_accuracy: 0.9453
Epoch 14/25
50000/50000 [==============================] - 1s 21us/sample - loss: 1.2835 - accuracy: 0.4800 - val_loss: 0.7398 - val_accuracy: 0.9520
Epoch 15/25
50000/50000 [==============================] - 1s 23us/sample - loss: 1.2713 - accuracy: 0.4790 - val_loss: 0.6975 - val_accuracy: 0.9543
Epoch 16/25
50000/50000 [==============================] - 1s 22us/sample - loss: 1.2555 - accuracy: 0.4828 - val_loss: 0.6676 - val_accuracy: 0.9558
Epoch 17/25
50000/50000 [==============================] - 1s 24us/sample - loss: 1.2494 - accuracy: 0.4799 - val_loss: 0.6401 - val_accuracy: 0.9576
Epoch 18/25
50000/50000 [==============================] - 1s 22us/sample - loss: 1.2384 - accuracy: 0.4820 - val_loss: 0.6124 - val_accuracy: 0.9585
Epoch 19/25
50000/50000 [==============================] - 1s 23us/sample - loss: 1.2414 - accuracy: 0.4775 - val_loss: 0.5897 - val_accuracy: 0.9596
Epoch 20/25
50000/50000 [==============================] - 1s 22us/sample - loss: 1.2233 - accuracy: 0.4834 - val_loss: 0.5721 - val_accuracy: 0.9600
Epoch 21/25
50000/50000 [==============================] - 1s 20us/sample - loss: 1.2050 - accuracy: 0.5010 - val_loss: 0.5570 - val_accuracy: 0.9609
Epoch 22/25
50000/50000 [==============================] - 1s 20us/sample - loss: 1.1897 - accuracy: 0.5114 - val_loss: 0.5193 - val_accuracy: 0.9641
Epoch 23/25
50000/50000 [==============================] - 1s 20us/sample - loss: 1.1653 - accuracy: 0.5175 - val_loss: 0.4916 - val_accuracy: 0.9631
Epoch 24/25
50000/50000 [==============================] - 1s 20us/sample - loss: 1.1488 - accuracy: 0.5216 - val_loss: 0.4757 - val_accuracy: 0.9651
Epoch 25/25
50000/50000 [==============================] - 1s 21us/sample - loss: 1.1467 - accuracy: 0.5151 - val_loss: 0.4604 - val_accuracy: 0.9631
10000/10000 - 0s - loss: 0.4609 - accuracy: 0.9620
</code></pre>
<p><img src="https://user-images.githubusercontent.com/41845290/114538555-79578500-9c8e-11eb-98df-d0ef0e800888.png" alt="output_30_1"></p>
<h1 id="mission-tdc--tdc-exercise">MISSION #TDC : TDC Exercise</h1>
<p><a href="https://www.coursera.org/learn/introduction-tensorflow/notebook/FExZ4/exercise-2-handwriting-recognition">https://www.coursera.org/learn/introduction-tensorflow/notebook/FExZ4/exercise-2-handwriting-recognition</a></p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
 
<span class="token comment"># YOUR CODE SHOULD START HERE</span>
<span class="token keyword">class</span> <span class="token class-name">callback</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>Callback<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#using callbacks to control training</span>
  <span class="token keyword">def</span> <span class="token function">on_epoch_end</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> epoch<span class="token punctuation">,</span> logs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span>logs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'acc'</span><span class="token punctuation">)</span> <span class="token operator">&gt;=</span> <span class="token number">0.99</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#99%의 정확도를 달성하면 학습을 중단합니다</span>
      <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n Reached 99% accuracy so canceling training!"</span><span class="token punctuation">)</span>
      self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>stop_training<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token comment"># YOUR CODE SHOULD END HERE</span>
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
 
<span class="token comment"># GRADED FUNCTION: train_mnist</span>
<span class="token keyword">def</span> <span class="token function">train_mnist</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
 
 
    mnist <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>mnist
 
    <span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span> <span class="token operator">=</span> mnist<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
    <span class="token comment"># YOUR CODE SHOULD START HERE</span>
    x_train<span class="token punctuation">,</span> x_test <span class="token operator">=</span> x_train<span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">,</span> x_test<span class="token operator">/</span><span class="token number">255</span>  <span class="token comment">#0-1값으로 정규화를합니다</span>
    <span class="token comment"># YOUR CODE SHOULD END HERE</span>
 
 
    model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token comment"># YOUR CODE SHOULD START HERE</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment">#60000만개의 28X28 이미지 인풋</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">)</span>
    <span class="token comment"># YOUR CODE SHOULD END HERE</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
 
    model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>
                  loss<span class="token operator">=</span><span class="token string">'sparse_categorical_crossentropy'</span><span class="token punctuation">,</span>
                  metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
 
    <span class="token comment"># YOUR CODE SHOULD START HERE</span>
    history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> callbacks<span class="token operator">=</span><span class="token punctuation">[</span>callback<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> history<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token comment"># test_loss, test_acc = model.evaluate(x_test, y_test)</span>
<span class="token comment"># print(test_loss, test_acc)</span>
train_mnist<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<pre><code>Epoch 1/10
60000/60000 [==============================] - 9s 152us/sample - loss: 0.1893 - acc: 0.9438
Epoch 2/10
60000/60000 [==============================] - 9s 151us/sample - loss: 0.0762 - acc: 0.9758
Epoch 3/10
60000/60000 [==============================] - 9s 146us/sample - loss: 0.0496 - acc: 0.9845
Epoch 4/10
60000/60000 [==============================] - 9s 148us/sample - loss: 0.0344 - acc: 0.9888
Epoch 5/10
59872/60000 [============================&gt;.] - ETA: 0s - loss: 0.0271 - acc: 0.9913
 Reached 99% accuracy so canceling training!
60000/60000 [==============================] - 9s 144us/sample - loss: 0.0271 - acc: 0.9913


([0, 1, 2, 3, 4], 0.99128336)
</code></pre>

